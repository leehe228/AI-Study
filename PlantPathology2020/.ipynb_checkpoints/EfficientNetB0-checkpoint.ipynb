{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9daf2a-dfa6-4ea1-9e44-1b15f962814a",
   "metadata": {},
   "source": [
    "# Plant Pathology 2020 - EfficientNetB0\n",
    "https://www.kaggle.com/c/plant-pathology-2020-fgvc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8c285-c0aa-459f-ae45-7c5b137d4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "op = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839e662-2853-471b-aa65-a25ea44cac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263a678-0a28-4260-9c55-6498f78aacd8",
   "metadata": {},
   "source": [
    "### CUDA GPU Device Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b37a6f-2f14-42b1-896e-ba70f7908836",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bc27b-4d82-4e8d-8e51-f8eb610aee6b",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661fe7f3-bde5-4a2a-bc90-d3f2a679a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/dmsai2/Desktop/AI-Study/PlantPathology2020/\"\n",
    "train_csv = op(path, \"train.csv\")\n",
    "train_path = op(path, \"images\", \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd4b64-ce56-48f7-be85-d1a65e318b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train:\", len(os.listdir(train_path)))\n",
    "n_train_data = len(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32891f11-618b-451a-a089-d506a38aac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7d3a1-6b88-43c9-bf92-a7d62af7a66e",
   "metadata": {},
   "source": [
    "### `read_image_resize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f997160-1ca3-433f-974e-2e09625875c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "tf = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef445082-ba20-4f13-8693-13aeed8f2b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_resize(img_path, dsize=(224, 224)):\n",
    "    assert type(dsize) == tuple and len(dsize) == 2\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, dsize)\n",
    "    tensor_img = tf(img)\n",
    "    return tensor_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966bd46-e298-4a0a-a7a5-0520c27bce4c",
   "metadata": {},
   "source": [
    "### `read_image_centercrop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df7a0b-0d88-424b-bfc6-0cd6fafa19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50269bc7-0478-475c-a34a-55bebf7413bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_cc = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, always_apply=True),\n",
    "    \n",
    "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), rotate_limit=30, p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
    "    A.CenterCrop(height=1365, width=1365, p=1.0),\n",
    "    A.Resize(height=224, width=224, p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fcabc-effc-41f9-9e8c-1f277274bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_centercrop(img_path, dsize=(224, 224)):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = aug_cc(image=img)['image']\n",
    "    tensor_img = tf(img)\n",
    "    return tensor_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6cced-7eaa-41e7-91a2-d379c8b68de3",
   "metadata": {},
   "source": [
    "### Transform for DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4efb52-36ec-44ba-96b1-e3b691823239",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f9b7b-d83b-40e3-a5c3-f99ae1a60610",
   "metadata": {},
   "source": [
    "### PyTorch Customized `Datasets` Class\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8dd8d-6084-4335-a4ae-40703fb1f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fcebce-13ee-4a14-9bec-faded67e790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantPathologyDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, header=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path + '.jpg')\n",
    "\n",
    "        # read image with resizing to (224, 224)\n",
    "        # image = read_image_resize(img_path + '.jpg')\n",
    "        \n",
    "        # read image with centercropping and resize to (224, 224)\n",
    "        # image = read_image_centercrop(img_path + '.jpg')\n",
    "    \n",
    "        label = np.argmax(self.img_labels.iloc[idx, 1:].values)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8f3a3-072d-43a5-af2a-8262c1846b8e",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd803c-70b4-4e2f-a31d-385bdb8ccc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PlantPathologyDataset(train_csv, train_path, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a272d77-ea17-4411-b4bc-b2c3c825f159",
   "metadata": {},
   "source": [
    "### Show Image Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ffbd2-8908-4eae-93a2-6472283b529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(data, is_test=False):\n",
    "    f, ax = plt.subplots(5, 5, figsize=(15, 10))\n",
    "    \n",
    "    for i in range(25):\n",
    "        img_dir = data.img_labels.iloc[i, 0]\n",
    "        img_data = cv2.imread(op(train_path, img_dir + '.jpg'))\n",
    "        label = np.argmax(data.img_labels.iloc[0, 1:].values)\n",
    "        \n",
    "        if label  == 0:  str_label = 'healthy'\n",
    "        elif label == 1:  str_label = 'multiple_diseases'\n",
    "        elif label == 2: str_label = 'rust'\n",
    "        else: str_label = 'scab'\n",
    "        if(is_test): str_label=\"None\"\n",
    "        \n",
    "        ax[i//5, i%5].imshow(img_data)\n",
    "        ax[i//5, i%5].axis('off')\n",
    "        ax[i//5, i%5].set_title(\"Label: {}\".format(str_label))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b521c-c41f-48fa-b57d-dab26230a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7610afc-8d86-4348-a0bd-c1d559d76be0",
   "metadata": {},
   "source": [
    "### Train Test Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b89da6-72ae-4e03-850c-67d62864ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = dataset_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89d152-4d7d-46c7-84a0-58debcbd0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73965efa-ad2c-48a1-894c-aca1fdbdb0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Testing Data Size : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edffddc-a696-4997-8cd6-0dba37a7125c",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbb1c7-f0ad-42c7-95fb-b57d81f3d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5987f6-be47-404e-aa79-d9aaca4a75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True, \n",
    "                              drop_last=True,\n",
    "                              num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=TEST_BATCH_SIZE, \n",
    "                             shuffle=True, \n",
    "                             drop_last=True,\n",
    "                             num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ab8b0-0503-4650-b523-9c675f4284e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {X_train.size()}\")\n",
    "print(f\"Labels batch shape: {y_train.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d84243-a8b7-4b88-a389-4d9714484c35",
   "metadata": {},
   "source": [
    "### Activation Function (Swish based ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29565a0-e61a-4819-b95e-25f51b1c0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_fn(x):\n",
    "    \"\"\" Swish activation function \"\"\"\n",
    "    return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0ffaa-8d90-4f23-9cd8-3adf1aa547d0",
   "metadata": {},
   "source": [
    "### EfficientNetB0 Model\n",
    "https://startnow95.tistory.com/4 <br>\n",
    "https://deep-learning-study.tistory.com/563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f190b-9fc8-4b01-accd-08d7e5bf6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n",
    "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361fa2a-ef04-4007-9b8f-706e7e610336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_connect(inputs, p, training):\n",
    "    \"\"\" Drop connect. \"\"\"\n",
    "    if not training: return inputs\n",
    "    batch_size = inputs.shape[0]\n",
    "    keep_prob = 1 - p\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype)  # uniform [0,1)\n",
    "    binary_tensor = torch.floor(random_tensor)\n",
    "    output = inputs / keep_prob * binary_tensor\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39903079-2809-4de3-9968-f0b0423fa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Mobile Inverted Residual Bottleneck Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride, expand_ratio, input_filters, output_filters, se_ratio, drop_n_add):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._bn_mom = 0.1\n",
    "        self._bn_eps = 1e-03\n",
    "        self.has_se = (se_ratio is not None) and (0 < se_ratio <= 1)\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.drop_n_add = drop_n_add\n",
    "\n",
    "        # Filter Expansion phase\n",
    "        inp = input_filters  # number of input channels\n",
    "        oup = input_filters * expand_ratio  # number of output channels\n",
    "        if expand_ratio != 1: # add it except at first block \n",
    "            self._expand_conv = Conv2dSamePadding(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = kernel_size\n",
    "        s = stride\n",
    "        self._depthwise_conv = Conv2dSamePadding(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise(conv filter by filter)\n",
    "            kernel_size=k, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1,int(input_filters * se_ratio))  # input channel * 0.25 ex) block2 => 16 * 0.25 = 4\n",
    "            self._se_reduce = Conv2dSamePadding(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = Conv2dSamePadding(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Output phase\n",
    "        final_oup = output_filters\n",
    "        self._project_conv = Conv2dSamePadding(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "        \n",
    "    def forward(self, inputs, drop_connect_rate=0.2):\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self.expand_ratio != 1:\n",
    "            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n",
    "        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "            \n",
    "        # Output phase\n",
    "        x = self._bn2(self._project_conv(x))\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        if self.drop_n_add == True:\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612866e-6ad1-4658-97c8-d7ee380f8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 0.1\n",
    "        bn_eps = 1e-03\n",
    "\n",
    "        # stem\n",
    "        in_channels = 3\n",
    "        out_channels = 32\n",
    "        self._conv_stem = Conv2dSamePadding(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([]) # list 형태로 model 구성할 때\n",
    "        # stage2 r1_k3_s11_e1_i32_o16_se0.25\n",
    "        self._blocks.append(MBConvBlock(kernel_size=3, stride=1, expand_ratio=1, input_filters=32, output_filters=16, se_ratio=0.25, drop_n_add=False))\n",
    "        # stage3 r2_k3_s22_e6_i16_o24_se0.25\n",
    "        self._blocks.append(MBConvBlock(3, 2, 6, 16, 24, 0.25, False))\n",
    "        self._blocks.append(MBConvBlock(3, 1, 6, 24, 24, 0.25, True))\n",
    "        # stage4 r2_k5_s22_e6_i24_o40_se0.25\n",
    "        self._blocks.append(MBConvBlock(5, 2, 6, 24, 40, 0.25, False))\n",
    "        self._blocks.append(MBConvBlock(5, 1, 6, 40, 40, 0.25, True))\n",
    "        # stage5 r3_k3_s22_e6_i40_o80_se0.25\n",
    "        self._blocks.append(MBConvBlock(3, 2, 6, 40, 80, 0.25, False))\n",
    "        self._blocks.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
    "        self._blocks.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
    "        # stage6 r3_k5_s11_e6_i80_o112_se0.25\n",
    "        self._blocks.append(MBConvBlock(5, 1, 6, 80,  112, 0.25, False))\n",
    "        self._blocks.append(MBConvBlock(5, 1, 6, 112, 112, 0.25, True))\n",
    "        self._blocks.append(MBConvBlock(5, 1, 6, 112, 112, 0.25, True))\n",
    "        # stage7 r4_k5_s22_e6_i112_o192_se0.25\n",
    "        self._blocks.append(MBConvBlock(5, 2, 6, 112, 192, 0.25, False))\n",
    "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
    "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
    "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
    "        # stage8 r1_k3_s11_e6_i192_o320_se0.25\n",
    "        self._blocks.append(MBConvBlock(3, 1, 6, 192, 320, 0.25, False))\n",
    "\n",
    "        # Head \n",
    "        in_channels = 320\n",
    "        out_channels = 1280\n",
    "        self._conv_head = Conv2dSamePadding(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        self._dropout = 0.2\n",
    "        self._num_classes = 10\n",
    "        self._fc = nn.Linear(out_channels, self._num_classes)\n",
    "\n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):          \n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "\n",
    "        # Convolution layers\n",
    "        x = self.extract_features(inputs)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        if self._dropout:\n",
    "            x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "        x = self._fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f480064-6f9e-4464-918f-bbf9200b7dbd",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d08ed-e592-4eb7-83fb-f60bec907785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "from torchsummary import summary as summary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e0392-92fa-4fb8-a069-4417aa6409d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientB0 = EfficientNet()\n",
    "summary_(efficientB0, (3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f556bb4-c2c8-4daf-aaea-4ebae2f2f3ca",
   "metadata": {},
   "source": [
    "### Neptune AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f918a4-4376-48ce-a074-6fdca51b3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06521e48-9c2d-4b8c-b88b-ba7bec2926e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"leehe228/plant-pathology\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI5MTRmYjRlNC0zODFlLTQ0ODItODY1MC1hZGQ0YTRhNDNlZjIifQ==\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eae25d-b0f7-411b-96d5-9cd4b7d2d4c0",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81c6eb-0dd0-4221-8eb8-080d0c32dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # lr 1e-3 ~ 1e-6\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"input_size\": 3 * 244 * 244,\n",
    "    \"num_epoch\": 50,\n",
    "    \"n_classes\": 4,\n",
    "    \"optimizer\": 'Adam',\n",
    "    \"criterion\": 'CrossEntropyLoss',\n",
    "    \"preproc_type\": \"centercrop\",\n",
    "    \"model\":\"ResNet50\",\n",
    "    \"library\":\"PyTorch\",\n",
    "    \"device\": str(device)\n",
    "}\n",
    "# add parameters\n",
    "run[\"parameters\"] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071267ce-8839-4fe0-a488-49d80c8ecc5f",
   "metadata": {},
   "source": [
    "### Optimizer and Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a9338-e73a-484e-9459-a4b1413e0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(res50.parameters(), lr=params['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289103e-4fea-462f-a447-6e129fb1465c",
   "metadata": {},
   "source": [
    "### Metric: ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c225bd0-aff1-4811-85b3-905203006dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics.aggregation.auc import AUC\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a1301-82ef-4d10-9c9c-3ae4fd85a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_auc = AUC()\n",
    "metric_auc = AUROC(task=\"multiclass\", num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125054e5-e8a8-4fe0-b7b4-0c2c8bd1807c",
   "metadata": {},
   "source": [
    "### Learning Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf0b37-38b4-4e71-8689-3f8b6ba3171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_max : number of iter\n",
    "# eta_min : min value of learning rate\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, \n",
    "                                                       T_max=5, \n",
    "                                                       eta_min=1e-6,\n",
    "                                                       last_epoch=-1,\n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023b84e-dc70-4b9d-b88b-065ad746d3c9",
   "metadata": {},
   "source": [
    "### Training Funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c049c-ab50-4c48-8eee-5af428cfc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7788399-2133-48d2-a575-53d62b2344ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params, criterion, optimizer):\n",
    "    for epoch in range(0, params['num_epoch']):\n",
    "        print(f\"epoch {epoch + 1}.\")\n",
    "        \n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # data, label 분리\n",
    "            x_train, y_train = data\n",
    "            \n",
    "            # y_train to one_hot_encoding\n",
    "            labels = F.one_hot(y_train, num_classes=4).double()\n",
    "        \n",
    "            inputs = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 이전 batch에서 계산된 가중치 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + back propagation\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # calculate loss, acc, roc auc\n",
    "            train_loss = criterion(outputs, labels)\n",
    "            train_acc = (torch.sum(preds == torch.argmax(labels, dim=1))).sum().item() / len(inputs) \n",
    "            train_auc = metric_auc(labels, preds).item()\n",
    "            \n",
    "            print(f\"batch {i}/{n_train_data//BATCH_SIZE} acc:{train_acc}, auc:{train_auc}, loss:{train_loss}\")\n",
    "            \n",
    "            # training batch loss and accuracy, auc\n",
    "            run[\"train/batch/loss\"].append(train_loss)\n",
    "            run[\"train/batch/acc\"].append(train_acc)\n",
    "            run['train/batch/auc'].append(train_auc)\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            metric_auc.reset()\n",
    "            \n",
    "        optim_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        print(f\"learning rate epoch {epoch} : {optim_lr}\")\n",
    "        run[\"train/epoch/lr\"].append(optim_lr)\n",
    "        \n",
    "        # scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # empty GPU RAM\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # test accuracy\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        accuracy = []\n",
    "        auc = []\n",
    "        losses = []\n",
    "        \n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            x_train, y_train = data\n",
    "            \n",
    "            # y_train to one_hot_encoding\n",
    "            labels = F.one_hot(y_train, num_classes=4).double()\n",
    "        \n",
    "            inputs = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (torch.sum(preds == torch.argmax(labels, dim=1))).sum().item()\n",
    "            test_loss = criterion(outputs, labels).item()\n",
    "            test_auc = (metric_auc(labels, preds)).item()\n",
    "            test_accuracy = correct / total\n",
    "        \n",
    "            run[\"test/batch/loss\"].append(test_loss)\n",
    "            run[\"test/batch/acc\"].append(test_accuracy)\n",
    "            run['test/batch/auc'].append(test_auc)\n",
    "            \n",
    "            accuracy.append(test_accuracy)\n",
    "            auc.append(test_auc)\n",
    "            losses.append(test_loss)\n",
    "            metric_auc.reset()\n",
    "        \n",
    "        # empty GPU RAM\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_epochs = params[\"num_epoch\"]\n",
    "        print(f\"epoch: {epoch+1}/{num_epochs}, Test Loss: {np.mean(losses)}, Test Acc: {np.mean(accuracy)}, Test AUC: {np.mean(auc)}\")\n",
    "        print(\"\\n\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        run[\"test/epoch/loss\"].append(np.mean(losses))\n",
    "        run[\"test/epoch/acc\"].append(np.mean(accuracy))\n",
    "        run['test/epoch/auc'].append(np.mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa6652-7add-4773-952d-96bf3876579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(efficientB0, params, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7dba6-2f99-406c-93f1-08ef8300d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientB0.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65580d05-4446-4625-bf5d-39f12584621a",
   "metadata": {},
   "source": [
    "### Save Model State "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a47819-ec7f-4f75-aba5-84f515e70730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37905a83-2063-4b0e-8601-d0d82e338a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientB0.state_dict(), 'model_weight_efficientB0_230513(1).pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042f8d8-4612-4cb8-abd7-f0ffd8f01b07",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00b362-b9ff-4502-870a-cf075ca6ea8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe0d55-c976-45dc-b035-e0078ff1c2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58118079-5d5f-4381-997e-69884ad2e491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
