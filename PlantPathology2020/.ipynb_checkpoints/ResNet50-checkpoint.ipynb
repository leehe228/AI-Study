{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94323808-3b4b-492b-affe-dc8ea5140e69",
   "metadata": {},
   "source": [
    "# Plant Pathology 2020 - ResNet50\n",
    "https://www.kaggle.com/c/plant-pathology-2020-fgvc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136ec2b-4a95-4a09-bce5-b9241521bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "op = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327697b-a63a-4737-83aa-ed1f60b7374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a6cd4-aa84-4820-bf2e-609148501a27",
   "metadata": {},
   "source": [
    "### CUDA GPU Device Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6907eb3-16ce-4044-bd64-85ff738806c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3555fd-869d-4db9-873d-9dbe910bffeb",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1197a30-5c53-4b78-9349-b70b49e1aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 설정\n",
    "path = \"/home/dmsai2/Desktop/AI-Study/PlantPathology2020/\"\n",
    "# annotation 적힌 csv 파일\n",
    "train_csv = op(path, \"train.csv\")\n",
    "# 이미지 파일 path\n",
    "train_path = op(path, \"images\", \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac412b-6ca4-4fcd-b55c-2f4c19751f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시킬 이미지 파일 개수\n",
    "print(\"train:\", len(os.listdir(train_path)))\n",
    "n_train_data = len(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e9344-0a1c-46b8-bb47-661bb2aa7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ac4b5-1873-483e-b7e2-8661029b9de1",
   "metadata": {},
   "source": [
    "### `read_image_resize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaee872-5ecc-445a-a01c-a36cc89106f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "tf = transforms.ToTensor()\n",
    "normalizer = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51007519-c994-4895-a142-f849c2a9221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽어서 단순히 224 224로 resize\n",
    "def read_image_resize(img_path, dsize=(224, 224)):\n",
    "    assert type(dsize) == tuple and len(dsize) == 2\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, dsize)\n",
    "    tensor_img = normalizer(tf(img))\n",
    "    return tensor_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f91ca-cc9d-437a-b303-26fd2011f2ff",
   "metadata": {},
   "source": [
    "### `read_image_centercrop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dccf44-304c-4962-b3e8-30c217e14cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd0f4d-c19c-4ca2-a118-4f2519176926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 augmentation\n",
    "aug_cc = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, always_apply=True),\n",
    "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), rotate_limit=30, p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
    "    A.CenterCrop(height=1365, width=1365, p=1.0),\n",
    "    A.Resize(height=224, width=224, p=1)\n",
    "    # A.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6db05c-b74d-4628-a3f9-def7c04e886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽고 위 augmentation 적용하는 함수\n",
    "def read_image_centercrop(img_path, dsize=(224, 224)):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = aug_cc(image=img)['image']\n",
    "    tensor_img = tf(img)\n",
    "    tensor_img = normalizer(tensor_img)\n",
    "    return tensor_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e3ec8b-7176-46b5-ba65-8c6ffeaedd0f",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055d85b-c4fa-4794-a60d-6bab34889956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9166d29-689e-4e5d-adcf-af89264ce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽을 때 변형해주는 함수\n",
    "tf = transforms.Compose([\n",
    "    # 사이즈를 255 x 255로 변형\n",
    "    transforms.Resize(256),\n",
    "    # 가운데 224 x 224를 잘라냄\n",
    "    transforms.CenterCrop(224),\n",
    "    # transforms.ToTensor(),\n",
    "    # IMAGENET normalize\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b51e9-b090-4e1e-a6ba-370ea27e7bf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorch Customized `Datasets` Class\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bca12b-af47-4ea6-8856-114c42b67261",
   "metadata": {},
   "source": [
    "one-hot encoding이 반드시 필요할까?\n",
    "\n",
    "https://study-grow.tistory.com/entry/pytorch-one-hot-encoding%EC%9D%B4-%EB%B0%98%EB%93%9C%EC%8B%9C-%ED%95%84%EC%9A%94%ED%95%A0%EA%B9%8C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8264a6c-95c8-4a64-a345-36323d6b9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc9f75-1321-4075-afc7-94ff68f23790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Datasets 클래스\n",
    "# 데이터셋을 클래스 형태로 보관\n",
    "class PlantPathologyDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, header=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path + '.jpg')\n",
    "        image = image.type(torch.FloatTensor)\n",
    "        image = image / 255.\n",
    "\n",
    "        # read image with resizing to (224, 224)\n",
    "        # image = read_image_resize(img_path + '.jpg')\n",
    "        \n",
    "        # read image with centercropping and resize to (224, 224)\n",
    "        # image = read_image_centercrop(img_path + '.jpg')\n",
    "    \n",
    "        label = np.argmax(self.img_labels.iloc[idx, 1:].values)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        # print(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ee0cb-3830-4511-a5b3-b3960dad8029",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3061b-4eb2-4ec3-a538-f1e38e28f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 클래스로 데이터셋 생성\n",
    "# annotation csv, 파일 경로, 위에서 정의한 transform 함께 넘김\n",
    "dataset = PlantPathologyDataset(train_csv, train_path, transform=tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbe26d-0252-4fd2-8631-75fe301cf101",
   "metadata": {},
   "source": [
    "### Show Image Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd48b2-21e9-4b86-9e0c-b44c01866fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 예시 보여주는 함수\n",
    "def show_images(data, is_test=False):\n",
    "    f, ax = plt.subplots(5, 5, figsize=(15, 10))\n",
    "    \n",
    "    for i in range(25):\n",
    "        img_dir = data.img_labels.iloc[i, 0]\n",
    "        img_data = cv2.imread(op(train_path, img_dir + '.jpg'))\n",
    "        label = np.argmax(data.img_labels.iloc[0, 1:].values)\n",
    "        \n",
    "        if label  == 0:  str_label = 'healthy'\n",
    "        elif label == 1:  str_label = 'multiple_diseases'\n",
    "        elif label == 2: str_label = 'rust'\n",
    "        else: str_label = 'scab'\n",
    "        if(is_test): str_label=\"None\"\n",
    "        \n",
    "        ax[i//5, i%5].imshow(img_data)\n",
    "        ax[i//5, i%5].axis('off')\n",
    "        ax[i//5, i%5].set_title(\"Label: {}\".format(str_label))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862de67b-e841-486c-a1e7-4a488ef7fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416506d-5fdf-4d6f-8682-a3b568365554",
   "metadata": {},
   "source": [
    "### Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc7ca5-cf83-4c04-a501-c6dd0864423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 학습용, 테스트용으로 분리\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = dataset_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641537a-7192-4b19-bd5f-091aef5775a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d626b4-a60b-4407-b498-657860e9d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Testing Data Size : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671c008-cf99-42a9-b16e-6888a784d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac7874-c66c-46d8-8bfa-f712530db369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37e90d-bf41-4810-ace4-5cf4e82905b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {X_train.size()}\")\n",
    "print(f\"Labels batch shape: {y_train.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396287c5-397c-41b2-b154-6c20e31b10f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c878322-dc38-43a5-9cef-3941ad7c59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801439c0-c5dd-4db9-a288-195f77dfece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation=True, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.activation:\n",
    "            return self.batchnorm(self.conv(x))\n",
    "        else:\n",
    "            return self.relu(self.batchnorm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca9ce6-ef16-423d-a6ff-477ffafba28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, red_channels, out_channels, is_plain=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.is_plain = is_plain\n",
    "        \n",
    "        if in_channels == 64:\n",
    "            self.convseq = nn.Sequential(\n",
    "                ConvBlock(in_channels, red_channels, kernel_size=1, padding=0),\n",
    "                ConvBlock(red_channels, red_channels, kernel_size=3, padding=1),\n",
    "                ConvBlock(red_channels, out_channels, activation=False, kernel_size=1, padding=0)\n",
    "            )\n",
    "            self.iden = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        elif in_channels == out_channels:\n",
    "            self.convseq = nn.Sequential(\n",
    "                ConvBlock(in_channels, red_channels, kernel_size=1, padding=0),\n",
    "                ConvBlock(red_channels, red_channels, kernel_size=3, padding=1),\n",
    "                ConvBlock(red_channels, out_channels, activation=False, kernel_size=1, padding=0)\n",
    "            )\n",
    "            self.iden = nn.Identity()\n",
    "        else:\n",
    "            self.convseq = nn.Sequential(\n",
    "                ConvBlock(in_channels, red_channels, kernel_size=1, padding=0, stride=2),\n",
    "                ConvBlock(red_channels, red_channels, kernel_size=3, padding=1),\n",
    "                ConvBlock(red_channels, out_channels, activation=False, kernel_size=1, padding=0)\n",
    "            )\n",
    "            self.iden = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        y = self.convseq(x)\n",
    "        if self.is_plain:\n",
    "            x = y\n",
    "        else:\n",
    "            x = y + self.iden(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdfb336-17e2-40a7-9b7f-dd10990a1ba5",
   "metadata": {},
   "source": [
    "**Pytorch Gloabl Average Pooling** <br>\n",
    "https://gaussian37.github.io/dl-concept-global_average_pooling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a7722-baa9-4034-96af-18e0ab7d71aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000, is_plain=False):\n",
    "        self.num_classes = num_classes\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2_x = nn.Sequential(\n",
    "            ResBlock(64, 64, 256, is_plain),\n",
    "            ResBlock(256, 64, 256, is_plain),\n",
    "            ResBlock(256, 64, 256, is_plain)\n",
    "        )\n",
    "        \n",
    "        self.conv3_x = nn.Sequential(\n",
    "            ResBlock(256, 128, 512, is_plain),\n",
    "            ResBlock(512, 128, 512, is_plain),\n",
    "            ResBlock(512, 128, 512, is_plain),\n",
    "            ResBlock(512, 128, 512, is_plain)\n",
    "        )\n",
    "        \n",
    "        self.conv4_x = nn.Sequential(\n",
    "            ResBlock(512, 256, 1024, is_plain),\n",
    "            ResBlock(1024, 256, 1024, is_plain),\n",
    "            ResBlock(1024, 256, 1024, is_plain),\n",
    "            ResBlock(1024, 256, 1024, is_plain),\n",
    "            ResBlock(1024, 256, 1024, is_plain),\n",
    "            ResBlock(1024, 256, 1024, is_plain)\n",
    "        )\n",
    "        \n",
    "        self.conv5_x = nn.Sequential(\n",
    "            ResBlock(1024, 512, 2048, is_plain),\n",
    "            ResBlock(2048, 512, 2048, is_plain),\n",
    "            ResBlock(2048, 512, 2048, is_plain),\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        self.gapool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # x = self.gapool(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee503ec8-d6fc-4ca8-8074-822e2271c7c6",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "https://pseudo-lab.github.io/pytorch-guide/docs/ch03-1.html\n",
    "https://velog.io/@gibonki77/ResNetwithPyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9745d22-5137-4946-8517-4a8483ea0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary as summary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5379ccd-6f0a-43ec-abd4-01792b698769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 모델 빌드하는 함수\n",
    "def build_resnet(input_shape=(3, 224, 224), is_50=True, is_plain=False, **kwargs):\n",
    "    x = torch.randn(2, *input_shape).to(device)\n",
    "    \n",
    "    if is_50:\n",
    "        model = ResNet(is_plain=is_plain, **kwargs).to(device)\n",
    "        assert model(x).shape == torch.Size([2, model.num_classes])\n",
    "        \n",
    "        if is_plain == False:\n",
    "            print(\"ResNet50 Created\")\n",
    "        if is_plain == True:\n",
    "            print(\"PlainNet50 Created\")\n",
    "            \n",
    "        print(summary_(model, (3, 224, 224), batch_size=2))\n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        model = ResNet_34(is_plain=is_plain).to(device)\n",
    "        assert model(x).shape == torch.Size([2, model.num_classes])\n",
    "        \n",
    "        if is_plain == False:\n",
    "            print(\"ResNet34 Created\")\n",
    "        if is_plain == True:\n",
    "            print(\"PlainNet34 Created\")\n",
    "\n",
    "        print(summary_(model, (3, 224, 224), batch_size=2))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a25917-deaa-4f56-ab0f-e4c893346f1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 빌드\n",
    "res50 = build_resnet(is_plain=True, num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27d3af-db85-46e3-9125-e9278fb7afc1",
   "metadata": {},
   "source": [
    "### Neptune AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055c469-b8ee-4ad4-8999-782141510855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2fc97-a4f4-4f84-b5d3-77d539b0e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"leehe228/plant-pathology\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI5MTRmYjRlNC0zODFlLTQ0ODItODY1MC1hZGQ0YTRhNDNlZjIifQ==\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd657a4-a799-491f-9ac3-e867ce6344fd",
   "metadata": {},
   "source": [
    "### Params\n",
    "https://torchmetrics.readthedocs.io/en/stable/classification/auroc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78a064-9681-4741-9f70-900d07c7cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # lr 1e-3 ~ 1e-6\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"input_size\": 3 * 244 * 244,\n",
    "    \"num_epoch\": 75,\n",
    "    \"n_classes\": 4,\n",
    "    \"optimizer\": 'Adam',\n",
    "    \"criterion\": 'CrossEntropyLoss',\n",
    "    \"preproc_type\": \"centercrop\",\n",
    "    \"model\":\"ResNet50\",\n",
    "    \"library\":\"PyTorch\",\n",
    "    \"normalized\":\"imagenet\",\n",
    "    \"scheduler\":\"none\",\n",
    "    \"device\": str(device)\n",
    "}\n",
    "# add parameters\n",
    "run[\"parameters\"] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5596667-4785-4f8f-bb05-0264075ac1a1",
   "metadata": {},
   "source": [
    "### Optimizer and Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a0c18-2089-4903-8516-7430e99b35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(res50.parameters(), lr=params['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cb51d-17ec-4862-a071-988ba68c42a5",
   "metadata": {},
   "source": [
    "### Metric: ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b175b-8054-40ff-8dce-fbdebd3df524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics.aggregation.auc import AUC\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5fef6-c00b-4dc8-beaa-76de64f38d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_auc = AUC()\n",
    "metric_auc = AUROC(task=\"multiclass\", num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa43eb-97be-4aa8-a13a-aa8de6b53ec9",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb802e53-9956-41d7-bcdd-7ad355aeb3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer,\n",
    "#                                                            T_0=10, \n",
    "#                                                            T_mult=1, \n",
    "#                                                            eta_min=0.001, \n",
    "#                                                            last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bbca4f-4088-44ab-a253-ba2a7122c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_max : number of iter\n",
    "# eta_min : min value of learning rate\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, \n",
    "#                                                        T_max=5, \n",
    "#                                                        eta_min=1e-6,\n",
    "#                                                        last_epoch=-1,\n",
    "#                                                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3b6a9-26dc-499d-9d81-a68c8132c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "#                                                        mode='max',\n",
    "#                                                        factor=0.1,\n",
    "#                                                        patience=5,\n",
    "#                                                        threshold=0.0001,\n",
    "#                                                        threshold_mode='rel',\n",
    "#                                                        cooldown=0,\n",
    "#                                                        min_lr=1e-4,\n",
    "#                                                        eps=1e-08,\n",
    "#                                                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c17f07-de4a-429a-a542-429eb019146d",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b82d8-aadc-417a-ab89-8564d3e4a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch callback can use with pytorch lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6914d2-11e8-4543-ac1f-c95ebf2f0885",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Function\n",
    "https://2021-01-06getstarted.tistory.com/m/49 <br>\n",
    "https://pseudo-lab.github.io/pytorch-guide/docs/ch04-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f40afc-4619-42e0-ba8d-181caacf7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0c60d-b76e-4ed6-85b6-d56cf5246268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params, criterion, optimizer):\n",
    "    \n",
    "    optim_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    run[\"train/epoch/lr\"].append(optim_lr)\n",
    "        \n",
    "    for epoch in range(0, params['num_epoch']):\n",
    "        print(f\"epoch {epoch + 1}.\")\n",
    "        \n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # data, label 분리\n",
    "            x_train, y_train = data\n",
    "            \n",
    "            # y_train to one_hot_encoding\n",
    "            labels = F.one_hot(y_train, num_classes=4).double()\n",
    "            \n",
    "            # GPU용으로 변환\n",
    "            inputs = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 이전 batch에서 계산된 가중치 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + back propagation\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # calculate loss, acc, roc auc\n",
    "            train_loss = criterion(outputs, labels)\n",
    "            train_acc = (torch.sum(preds == torch.argmax(labels, dim=1))).sum().item() / len(inputs) \n",
    "            train_auc = metric_auc(labels, preds).item()\n",
    "            \n",
    "            print(f\"batch {i}/{n_train_data//BATCH_SIZE} acc:{train_acc}, auc:{train_auc}, loss:{train_loss}\")\n",
    "            \n",
    "            # training batch loss and accuracy, auc\n",
    "            run[\"train/batch/loss\"].append(train_loss)\n",
    "            run[\"train/batch/acc\"].append(train_acc)\n",
    "            run['train/batch/auc'].append(train_auc)\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            metric_auc.reset()\n",
    "        \n",
    "        # empty GPU RAM\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # test accuracy\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        accuracy = []\n",
    "        auc = []\n",
    "        losses = []\n",
    "        \n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            x_train, y_train = data\n",
    "            \n",
    "            # y_train to one_hot_encoding\n",
    "            labels = F.one_hot(y_train, num_classes=4).double()\n",
    "        \n",
    "            inputs = x_train.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (torch.sum(preds == torch.argmax(labels, dim=1))).sum().item()\n",
    "            test_loss = criterion(outputs, labels).item()\n",
    "            test_auc = (metric_auc(labels, preds)).item()\n",
    "            test_accuracy = correct / total\n",
    "        \n",
    "            run[\"test/batch/loss\"].append(test_loss)\n",
    "            run[\"test/batch/acc\"].append(test_accuracy)\n",
    "            run['test/batch/auc'].append(test_auc)\n",
    "            \n",
    "            accuracy.append(test_accuracy)\n",
    "            auc.append(test_auc)\n",
    "            losses.append(test_loss)\n",
    "            metric_auc.reset()\n",
    "        \n",
    "        # empty GPU RAM\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_epochs = params[\"num_epoch\"]\n",
    "        print(f\"epoch: {epoch+1}/{num_epochs}, Test Loss: {np.mean(losses)}, Test Acc: {np.mean(accuracy)}, Test AUC: {np.mean(auc)}\")\n",
    "        print(\"\\n\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        run[\"test/epoch/loss\"].append(np.mean(losses))\n",
    "        run[\"test/epoch/acc\"].append(np.mean(accuracy))\n",
    "        run['test/epoch/auc'].append(np.mean(auc))\n",
    "        \n",
    "        # scheduler\n",
    "        # scheduler.step(np.mean(auc))\n",
    "        \n",
    "        optim_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        print(f\"learning rate epoch {epoch} : {optim_lr}\")\n",
    "        run[\"train/epoch/lr\"].append(optim_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b99fd-e7ad-466f-9da7-0816612451a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(res50, params, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1d2f6-62ad-427d-bab2-9388b27fb939",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "res50.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81853e97-35b3-43ed-a1f9-c10dcef81bc0",
   "metadata": {},
   "source": [
    "### Save Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b9e2a-a1ef-45af-a02e-73c50c765f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514773f-82b0-493b-b219-69237552f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(res50.state_dict(), 'model_weight_230513(6)_epoch61.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d5a22-3bd9-4349-bb15-e219ea8d1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res50.load_state_dict(torch.load('model_weight.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60ae07-95da-4dbd-bd4f-6861e760eabf",
   "metadata": {},
   "source": [
    "### Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fccf1-be41-4aaa-b95e-8ce05ffdb0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "pred_list.append(['image_id', 'healthy', 'multiple_diseases', 'rust', 'scab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4395dbb-246f-4af3-8e81-e0a04351d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv('test.csv')\n",
    "submission_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56062e4e-63f6-4035-96f2-1748ba4a8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/home/dmsai2/Desktop/AI-Study/PlantPathology2020/images/Submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e60e4-abba-404d-9057-f7c2cbaed391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d75bba-5a02-49c1-b802-d23071784a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(submission_data))):\n",
    "    img_title = submission_data.iloc[i, 0]\n",
    "    img_dir = img_title + '.jpg'\n",
    "    # print(op(submission_path, img_dir))\n",
    "    \n",
    "    image = read_image(op(submission_path, img_dir))\n",
    "    image = image.type(torch.FloatTensor)\n",
    "    img = image / 255.\n",
    "    img = tf(img)\n",
    "    img = img.reshape(1, 3, 224, 224)\n",
    "    inputs = img.to(device)\n",
    "    # print(inputs.shape)\n",
    "    outputs = res50(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    ans = [img_title, 0, 0, 0, 0]\n",
    "    ans[int(preds) + 1] = 1\n",
    "    pred_list.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef7fa1-e50f-4435-9ca7-cc1555f19382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3650d94-22ae-4a26-9cc5-9e6383987cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1776c50-dcc9-49b8-ae93-ed1236d52d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0bb9bb-7715-4c33-adb0-229c5315925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('./submission/submission_cc7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45c7a4-3b98-4227-9c28-5d0cc6cf0c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc496e8-1c97-4277-b371-89e02e6bd640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
